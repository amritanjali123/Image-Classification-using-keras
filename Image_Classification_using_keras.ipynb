{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Classification_using_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amritanjali123/Image-Classification-using-keras/blob/master/Image_Classification_using_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cxE3yc3ijDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "5c657d3c-7e79-4b21-ad86-2d980bbff191"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZVnRgIFih_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycFYPVyZPm0S",
        "colab_type": "text"
      },
      "source": [
        "**In this project I am using the keggle data set contains four classes of Image and I am useing keras to build model by those Image and then I am predicting the images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4lD0al-Qd00",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JO_U8KsEUyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "9c39713f-b83e-497a-a1f2-0736dc330043"
      },
      "source": [
        "\n",
        "# Installing Keras\n",
        "# pip install --upgrade keras\n",
        "\n",
        "# Part 1 - Building the CNN\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
        "classifier.add(Dense(output_dim =4, activation = 'softmax'))\n",
        "\n",
        "# Compiling the CNN\n",
        "#classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "#classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0w7KJsYpLJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "59834e24-a625-45ec-ea39-9e43ae4621fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYungOo9EnDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZGBAtAtNJeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7f2080f-37f0-4809-e518-4ccbf85047c2"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/gdrive/My Drive/kaggle/Project/data/Untitled folder/data',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 446 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPoM3KCU0xDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ9kPE8OjjXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a57af22-b418-4420-ed1d-865629512648"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/gdrive/My Drive/kaggle/Project/data/test/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2023 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e4LUMysKd4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "878bbe80-4b54-49d5-b1e2-3044a335ad55"
      },
      "source": [
        "classifier.fit_generator(training_set,\n",
        "                         samples_per_epoch = 446,\n",
        "                         nb_epoch = 20,\n",
        "                         # validation_data = 0.25,\n",
        "                         #nb_val_samples = 2000\n",
        "                        )\n",
        "                         \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=13, epochs=20)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "13/13 [==============================] - 2s 176ms/step - loss: 0.7596 - acc: 0.6803\n",
            "Epoch 2/20\n",
            "13/13 [==============================] - 2s 157ms/step - loss: 0.6152 - acc: 0.7843\n",
            "Epoch 3/20\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 0.5947 - acc: 0.7607\n",
            "Epoch 4/20\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 0.4640 - acc: 0.8305\n",
            "Epoch 5/20\n",
            "13/13 [==============================] - 2s 168ms/step - loss: 0.4817 - acc: 0.8125\n",
            "Epoch 6/20\n",
            "13/13 [==============================] - 2s 161ms/step - loss: 0.4044 - acc: 0.8567\n",
            "Epoch 7/20\n",
            "13/13 [==============================] - 2s 157ms/step - loss: 0.4221 - acc: 0.8526\n",
            "Epoch 8/20\n",
            "13/13 [==============================] - 2s 140ms/step - loss: 0.4142 - acc: 0.8462\n",
            "Epoch 9/20\n",
            "13/13 [==============================] - 2s 152ms/step - loss: 0.3092 - acc: 0.8723\n",
            "Epoch 10/20\n",
            "13/13 [==============================] - 2s 156ms/step - loss: 0.3663 - acc: 0.8693\n",
            "Epoch 11/20\n",
            "13/13 [==============================] - 2s 158ms/step - loss: 0.3582 - acc: 0.8764\n",
            "Epoch 12/20\n",
            "13/13 [==============================] - 2s 156ms/step - loss: 0.3073 - acc: 0.8817\n",
            "Epoch 13/20\n",
            "13/13 [==============================] - 2s 157ms/step - loss: 0.3119 - acc: 0.8798\n",
            "Epoch 14/20\n",
            "13/13 [==============================] - 2s 152ms/step - loss: 0.3050 - acc: 0.8841\n",
            "Epoch 15/20\n",
            "13/13 [==============================] - 2s 148ms/step - loss: 0.3029 - acc: 0.8891\n",
            "Epoch 16/20\n",
            "13/13 [==============================] - 2s 159ms/step - loss: 0.2360 - acc: 0.9202\n",
            "Epoch 17/20\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 0.2119 - acc: 0.9207\n",
            "Epoch 18/20\n",
            "13/13 [==============================] - 2s 158ms/step - loss: 0.2103 - acc: 0.9223\n",
            "Epoch 19/20\n",
            "13/13 [==============================] - 2s 157ms/step - loss: 0.2491 - acc: 0.9109\n",
            "Epoch 20/20\n",
            "13/13 [==============================] - 2s 152ms/step - loss: 0.1911 - acc: 0.9327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff372a59f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZL_OkBGs6MR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle \n",
        "  \n",
        "# Save the trained model as a pickle string. \n",
        "saved_model = pickle.dumps(classifier) \n",
        "  \n",
        "# Load the pickled model \n",
        "knn_from_pickle = pickle.loads(saved_model) \n",
        "  \n",
        "# Use the loaded pickled model to make predictions \n",
        "from sklearn.externals import joblib \n",
        "\n",
        "# Save the model as a pickle in a file \n",
        "joblib.dump(classifier, 'cnnfile.pkl') \n",
        "\n",
        "# Load the model from the file \n",
        "knn_from_joblib = joblib.load('cnnfile.pkl') \n",
        "\n",
        "# Use the loaded model to make predictions \n",
        "#knn_from_joblib.predict(X_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXTvvZHjwTdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "c7b73303-c010-4b44-e6eb-b2bec6d215f2"
      },
      "source": [
        "from PIL import Image\n",
        "import PIL\n",
        "import pickle\n",
        "from sklearn.externals import joblib \n",
        "#knn_from_joblib = joblib.load('cnnfile.pkl') \n",
        "import numpy as np\n",
        "img = Image.open('/content/gdrive/My Drive/kaggle/Project/data/Untitled folder/data/humans/rider-107.jpg')\n",
        "#img = img.convert('L')\n",
        "#cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,255),2)    \n",
        "img = img.resize((64, 64), PIL.Image.ANTIALIAS)\n",
        "arr = np.array(img)\n",
        "img = np.reshape(img, (1, 64, 64, 3))\n",
        "img = img / 255\n",
        "result = classifier.predict(img)\n",
        "max=result[0][0]\n",
        "for i in range(1, 4): \n",
        "        if result[0][i] > max: \n",
        "            max = result[0][i]\n",
        "            i1=i\n",
        "\n",
        "print(i1+1)\n",
        "print(result[0][0])\n",
        "print(result[0][1])\n",
        "print(result[0][2])\n",
        "print(result[0][3])\n",
        "#classifier.predict_classes(training_set[1:5])\n",
        "#print(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "5.098754e-07\n",
            "0.0028793733\n",
            "0.0015855914\n",
            "0.9955344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-ac531a646fcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             raise ValueError('Asked to retrieve element {idx}, '\n\u001b[1;32m     55\u001b[0m                              \u001b[0;34m'but the Sequence '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'slice' and 'int'"
          ]
        }
      ]
    }
  ]
}